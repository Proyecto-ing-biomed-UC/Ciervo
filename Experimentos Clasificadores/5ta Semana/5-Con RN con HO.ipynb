{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de datos que permita reconocer la marcha - Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T18:16:54.296639Z",
     "start_time": "2024-09-02T18:16:32.395138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: ciervo in /opt/conda/lib/python3.6/site-packages (2024.8.30)\n",
      "importing Jupyter notebook from functions.ipynb\n",
      "Requirement already up-to-date: ciervo in /opt/conda/lib/python3.6/site-packages (2024.8.30)\n",
      "fatal: destination path 'balu3' already exists and is not an empty directory.\n",
      "Processing ./balu3\n",
      "Building wheels for collected packages: balu3\n",
      "  Building wheel for balu3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for balu3: filename=balu3-1.0-cp36-none-any.whl size=43719 sha256=d24741c6a5a6a4dde0cf16dcf6cf84db87884d9eb30cb0a003767c755c2d3700\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ahq3rgx0/wheels/a0/cb/32/94ff1ea5874a8b4908404cf9d18fac5aec5e0e168cc5a148c1\n",
      "Successfully built balu3\n",
      "Installing collected packages: balu3\n",
      "  Found existing installation: balu3 1.0\n",
      "    Uninstalling balu3-1.0:\n",
      "      Successfully uninstalled balu3-1.0\n",
      "Successfully installed balu3-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ciervo --upgrade\n",
    "#!pip install import-ipynb\n",
    "import import_ipynb\n",
    "\n",
    "from functions import * \n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from ciervo.plots import emg_plot\n",
    "import torch.nn as nn\n",
    "from ciervo.io import load_data\n",
    "from ciervo.models import label_data, train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T18:17:00.425924Z",
     "start_time": "2024-09-02T18:16:54.300984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2.29 hours\n"
     ]
    }
   ],
   "source": [
    "data_files = load_data('data/marcha_larga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T18:21:14.704058Z",
     "start_time": "2024-09-02T18:21:14.677126Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(data_files, window_size, overlap, num_fases):\n",
    "    # Cargar y preparar los datos\n",
    "    labeled_data = label_data(data_files, num_fases=num_fases)\n",
    "    \n",
    "    # Dividir los datos en entrenamiento y prueba\n",
    "    print(len(labeled_data[0].columns))\n",
    "    train_window, train_labels, test_window, test_labels = train_test_split(\n",
    "        labeled_data,\n",
    "        columna=[\"EMG_Isquio\", \"EMG_Cuadriceps\", \"EMG_AductorLargo\"],\n",
    "        window_size=window_size,\n",
    "        test_size=0.2,\n",
    "        overlap=overlap,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Procesar los datos\n",
    "    train_data = label_data_and_features(train_window, divide=3)\n",
    "    test_data = label_data_and_features(test_window, divide=3)\n",
    "    \n",
    "    # Seleccionar características\n",
    "    train_data, test_data = sfs_selection(train_data, test_data, train_labels, n_indices=5)\n",
    "    \n",
    "    # Entrenar y evaluar Simple NN\n",
    "    input_size = train_data.shape[1]\n",
    "    hidden_size = 100\n",
    "    output_size = num_fases\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 100\n",
    "    \n",
    "    model = SimpleNN(input_size, hidden_size, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loader, test_tensor, test_labels_tensor = prepare_data_SimpleNN(train_data, train_labels, test_data, test_labels)\n",
    "    train_model_SimpleNN(model, criterion, optimizer, train_loader, num_epochs)\n",
    "    accuracy_nn = evaluate_model_SimpleNN(model, test_tensor, test_labels_tensor)\n",
    "    \n",
    "    return accuracy_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T18:21:16.009979Z",
     "start_time": "2024-09-02T18:21:16.006288Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'window_size': [ 500],\n",
    "    'overlap': [0, 50],\n",
    "    'num_fases': [4, 8, 16]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T18:21:19.392959Z",
     "start_time": "2024-09-02T18:21:17.299148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'num_fases': 4, 'overlap': 0, 'window_size': 500}\n",
      "12\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 500 to array axis with dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-65ad403a1db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'window_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overlap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnum_fases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_fases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b9fff3dc0580>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(data_files, window_size, overlap, num_fases)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/ciervo/models/split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(data, columna, window_size, test_size, overlap, random_state)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 500 to array axis with dimension 3"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing with parameters: {params}\")\n",
    "    accuracy = evaluate_model(data_files,\n",
    "        window_size=params['window_size'],\n",
    "        overlap=params['overlap'],\n",
    "        num_fases=params['num_fases']\n",
    "    )\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(best_params)\n",
    "print(\"Best accuracy achieved:\")\n",
    "print(best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T18:17:04.317033Z",
     "start_time": "2024-09-02T18:16:33.069Z"
    }
   },
   "outputs": [],
   "source": [
    "data_files = load_data('data/marcha_larga')\n",
    "\n",
    "# Parámetros para la búsqueda en cuadrícula\n",
    "fases_to_test = [4, 8, 16]\n",
    "overlaps = [0, 50]\n",
    "window_sizes = [0.25, 0.5, 1, 2]  # en segundos\n",
    "SAMPLE_RATE=250\n",
    "# Convertir window_sizes de segundos a número de muestras\n",
    "window_sizes_samples = [int(size * SAMPLE_RATE) for size in window_sizes]\n",
    "\n",
    "# Crear listas para almacenar los resultados\n",
    "results_simple_nn = []\n",
    "results_cnn = []\n",
    "results_rnn = []\n",
    "\n",
    "# Generar todas las combinaciones de parámetros\n",
    "param_grid = {\n",
    "    'fases': fases_to_test,\n",
    "    'overlap': overlaps,\n",
    "    'window_size': window_sizes_samples\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "for params in grid:\n",
    "    num_fases = params['fases']\n",
    "    overlap = params['overlap']\n",
    "    window_size = params['window_size']\n",
    "    \n",
    "    print(f\"TESTING WITH Fases: {num_fases}, Overlap: {overlap}, Window Size: {window_size} samples...\")\n",
    "    \n",
    "    labeled_data = label_data(data_files, num_fases=num_fases)\n",
    "    \n",
    "    train_window, train_labels, test_window, test_labels = train_test_split(\n",
    "        labeled_data, \n",
    "        columna=[\"EMG_Isquio\",\"EMG_Cuadriceps\",\"EMG_AductorLargo\"],\n",
    "        window_size=window_size,\n",
    "        test_size=0.2,\n",
    "        overlap=overlap,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Train data: Extracted {train_window.shape[0]} samples with {train_window.shape[1]} features each.\")\n",
    "    print(f\"Test data: Extracted {test_window.shape[0]} samples with {test_window.shape[1]} features each.\")\n",
    "    \n",
    "    train_data = label_data_and_features(train_window, divide=3)\n",
    "    test_data = label_data_and_features(test_window, divide=3)\n",
    "    \n",
    "    train_data, test_data = sfs_selection(train_data, test_data, train_labels, n_indices=5)\n",
    "    print(f\"Train data: Extracted {train_data.shape[0]} samples with {train_data.shape[1]} features each.\")\n",
    "    print(f\"Test data: Extracted {test_data.shape[0]} samples with {test_data.shape[1]} features each.\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    \n",
    "    # Simple NN\n",
    "    print(\"Simple NN\")\n",
    "    input_size = train_data.shape[1]\n",
    "    hidden_size = 100\n",
    "    output_size = num_fases\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 100\n",
    "    \n",
    "    model = SimpleNN(input_size, hidden_size, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loader, test_tensor, test_labels_tensor = prepare_data_SimpleNN(train_data, train_labels, test_data, test_labels)\n",
    "    train_model_SimpleNN(model, criterion, optimizer, train_loader, num_epochs)\n",
    "    accuracy_nn = evaluate_model_SimpleNN(model, test_tensor, test_labels_tensor)\n",
    "    results_simple_nn.append((params, accuracy_nn))\n",
    "    \n",
    "    # CNN\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"CNN\")\n",
    "    train_loader, test_loader, test_labels_tensor, train_data_tensor = prepare_data_CNN(train_data, train_labels, test_data, test_labels)\n",
    "    input_length = train_data_tensor.shape[2]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    cnn_model = GaitCNN(input_length, num_fases=num_fases).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loss, test_loss = train_model_CNN(cnn_model, device, criterion, optimizer, train_loader, test_loader, num_epochs=100)\n",
    "    accuracy_cnn = evaluate_model_CNN(cnn_model, test_loader, test_labels_tensor)\n",
    "    results_cnn.append((params, accuracy_cnn))\n",
    "    \n",
    "    # RNN\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"RNN\")\n",
    "    train_data_rnn, test_data_rnn = preprocess_data_RNN(train_data, test_data)\n",
    "    input_size = train_data_rnn.shape[2]\n",
    "    hidden_size = 64\n",
    "    num_layers = 2\n",
    "    batch_size = 32\n",
    "    num_epochs = 150\n",
    "    \n",
    "    train_loader, test_loader = create_dataloaders_RNN(train_data_rnn, train_labels, test_data_rnn, test_labels, batch_size)\n",
    "    rnn_model = GaitRNN(input_size, hidden_size, num_layers, num_fases).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loss, test_loss = train_model_RNN(rnn_model, train_loader, test_loader, criterion, optimizer, num_epochs, device)\n",
    "    accuracy_rnn = evaluate_model_RNN(rnn_model, test_loader, test_labels, device)\n",
    "    results_rnn.append((params, accuracy_rnn))\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Results for Simple NN:\")\n",
    "for params, acc in results_simple_nn:\n",
    "    print(f\"Params: {params}, Accuracy: {acc}\")\n",
    "\n",
    "print(\"Results for CNN:\")\n",
    "for params, acc in results_cnn:\n",
    "    print(f\"Params: {params}, Accuracy: {acc}\")\n",
    "\n",
    "print(\"Results for RNN:\")\n",
    "for params, acc in results_rnn:\n",
    "    print(f\"Params: {params}, Accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
