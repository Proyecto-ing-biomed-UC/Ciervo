{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de datos que permita reconocer la marcha - Hold Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initial Setup (carga de libreri√≠as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:20:49.173800Z",
     "start_time": "2024-08-21T15:20:29.576925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from functions.ipynb\n",
      "Requirement already satisfied: ciervo in /opt/conda/lib/python3.8/site-packages (2024.8.23)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "fatal: destination path 'balu3' already exists and is not an empty directory.\n",
      "Processing ./balu3\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Building wheels for collected packages: balu3\n",
      "  Building wheel for balu3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for balu3: filename=balu3-1.0-py3-none-any.whl size=43718 sha256=86f904a8293e49d3a2022da14cd67aacca9451a7aaf012ce9e2b73f79e998873\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-12s6gj7q/wheels/1d/f1/b3/dfbb6908bffc070ba2baad77932ab66db0022561f2c4127596\n",
      "Successfully built balu3\n",
      "Installing collected packages: balu3\n",
      "  Attempting uninstall: balu3\n",
      "    Found existing installation: balu3 1.0\n",
      "    Uninstalling balu3-1.0:\n",
      "      Successfully uninstalled balu3-1.0\n",
      "Successfully installed balu3-1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from functions import * \n",
    "from ciervo.plots import emg_plot\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-21T18:28:57.879Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:20:50.683572Z",
     "start_time": "2024-08-21T15:20:49.177692Z"
    }
   },
   "outputs": [],
   "source": [
    "data_files = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:20:56.655594Z",
     "start_time": "2024-08-21T15:20:50.693901Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "step, emg, file= prepare_data(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Training and testing subsets // Classification & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:20:56.674657Z",
     "start_time": "2024-08-21T15:20:56.661335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definir las fases a probar\n",
    "fases_to_test = [4, 6, 8, 10, 12, 14, 16]\n",
    "\n",
    "# Crear listas para almacenar los resultados\n",
    "results_simple_nn = []\n",
    "results_cnn = []\n",
    "results_rnn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-21T15:20:30.241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH 4 PHASES...\n",
      "[28 26  8  5 14]\n",
      "Train data: Extracted 5156 samples with 5 features each.\n",
      "Test data: Extracted 2620 samples with 5 features each.\n",
      "-----------------------------------------------------------------------\n",
      "Simple NN\n",
      "Epoch [10/100], Loss: 0.6961105465888977\n",
      "Epoch [20/100], Loss: 0.0755750983953476\n",
      "Epoch [30/100], Loss: 0.4163396954536438\n",
      "Epoch [40/100], Loss: 0.6866856217384338\n",
      "Epoch [50/100], Loss: 0.1482744663953781\n",
      "Epoch [60/100], Loss: 0.06431372463703156\n",
      "Epoch [70/100], Loss: 0.5354350209236145\n",
      "Epoch [80/100], Loss: 0.03961857035756111\n",
      "Epoch [90/100], Loss: 1.2552785873413086\n",
      "Epoch [100/100], Loss: 0.2148297280073166\n",
      "Accuracy: 0.7015267175572519%\n",
      "-----------------------------------------------------------------------\n",
      "CNN\n",
      "Epoch [10/100], Train Loss: 0.37176113695274166, Val Loss: 0.6560580068972053\n",
      "Epoch [20/100], Train Loss: 0.33670889521822517, Val Loss: 0.8003597533920916\n",
      "Epoch [30/100], Train Loss: 0.31879787524173286, Val Loss: 0.7232423613711101\n",
      "Epoch [40/100], Train Loss: 0.30916202408664023, Val Loss: 0.7524149417877197\n",
      "Epoch [50/100], Train Loss: 0.3002702557010415, Val Loss: 0.7375072646068364\n",
      "Epoch [60/100], Train Loss: 0.29091012836606417, Val Loss: 0.7336816607815463\n",
      "Epoch [70/100], Train Loss: 0.2890843742377596, Val Loss: 0.7677934407824423\n",
      "Epoch [80/100], Train Loss: 0.28117517269227976, Val Loss: 0.7105742182310034\n",
      "Epoch [90/100], Train Loss: 0.2760772117540056, Val Loss: 0.7846548597260219\n",
      "Epoch [100/100], Train Loss: 0.274512301509579, Val Loss: 0.8374970380852862\n",
      "Accuracy of CNN: 0.6851145038167938\n",
      "-----------------------------------------------------------------------\n",
      "RNN\n",
      "Epoch 5/150, Train Loss: 0.5820130797815911, Val Loss: 0.6933948710197355\n",
      "Epoch 10/150, Train Loss: 0.4731267679620672, Val Loss: 0.7291195712438444\n",
      "Epoch 15/150, Train Loss: 0.44740143767845486, Val Loss: 0.6370257909704999\n",
      "Epoch 20/150, Train Loss: 0.42108035851040004, Val Loss: 0.6548487060680622\n",
      "Epoch 25/150, Train Loss: 0.4169907726255464, Val Loss: 0.7015388922356978\n",
      "Epoch 30/150, Train Loss: 0.39643441915604066, Val Loss: 0.6083655291941108\n",
      "Epoch 35/150, Train Loss: 0.38109167444485204, Val Loss: 0.7145693625618772\n",
      "Epoch 40/150, Train Loss: 0.34034552737886525, Val Loss: 0.6667991186060557\n",
      "Epoch 45/150, Train Loss: 0.31414812145593723, Val Loss: 0.7037943129132433\n",
      "Epoch 50/150, Train Loss: 0.3058426574240496, Val Loss: 0.7015695906266933\n",
      "Epoch 55/150, Train Loss: 0.300383624057343, Val Loss: 0.7338758883316342\n",
      "Epoch 60/150, Train Loss: 0.2875898700253463, Val Loss: 0.7657315556595965\n",
      "Epoch 65/150, Train Loss: 0.2856579053641101, Val Loss: 0.7657962323325437\n",
      "Epoch 70/150, Train Loss: 0.27947332912389145, Val Loss: 0.8040765609319617\n",
      "Epoch 75/150, Train Loss: 0.27382695811145286, Val Loss: 0.7090429420151362\n",
      "Epoch 80/150, Train Loss: 0.27511136629331256, Val Loss: 0.7759236126411252\n",
      "Epoch 85/150, Train Loss: 0.2641373638259132, Val Loss: 0.6951613022786814\n",
      "Epoch 90/150, Train Loss: 0.2642084544547546, Val Loss: 0.7387419755502445\n",
      "Epoch 95/150, Train Loss: 0.25813384503586057, Val Loss: 0.7235819959058994\n",
      "Epoch 100/150, Train Loss: 0.2502459220956137, Val Loss: 0.846366798005453\n",
      "Epoch 105/150, Train Loss: 0.24959601073261398, Val Loss: 0.7995763221165029\n",
      "Epoch 110/150, Train Loss: 0.24115122971987282, Val Loss: 0.7856583150058258\n",
      "Epoch 115/150, Train Loss: 0.2396414989122638, Val Loss: 0.7509891941416554\n",
      "Epoch 120/150, Train Loss: 0.24123075691822135, Val Loss: 0.7788624358249874\n",
      "Epoch 125/150, Train Loss: 0.23287670376400152, Val Loss: 0.7967230483162694\n",
      "Epoch 130/150, Train Loss: 0.2346158941954742, Val Loss: 0.7901210167059084\n",
      "Epoch 135/150, Train Loss: 0.22607773312447985, Val Loss: 0.78452899361529\n",
      "Epoch 140/150, Train Loss: 0.2141980896761388, Val Loss: 0.8958529957183977\n",
      "Epoch 145/150, Train Loss: 0.21936050151693232, Val Loss: 0.7701929893072058\n",
      "Epoch 150/150, Train Loss: 0.2026845888223177, Val Loss: 0.8392966720389157\n",
      "Accuracy of RNN: 0.7125954198473282\n",
      "-----------------------------------------------------------------------\n",
      "TESTING WITH 6 PHASES...\n",
      "[28 26  7  9  5]\n",
      "Train data: Extracted 7734 samples with 5 features each.\n",
      "Test data: Extracted 3930 samples with 5 features each.\n",
      "-----------------------------------------------------------------------\n",
      "Simple NN\n",
      "Epoch [10/100], Loss: 0.7307119965553284\n",
      "Epoch [20/100], Loss: 0.5797841548919678\n",
      "Epoch [30/100], Loss: 0.5141915082931519\n",
      "Epoch [40/100], Loss: 0.7532976269721985\n",
      "Epoch [50/100], Loss: 0.9139883518218994\n",
      "Epoch [60/100], Loss: 0.5213263630867004\n",
      "Epoch [70/100], Loss: 0.6624181866645813\n",
      "Epoch [80/100], Loss: 0.5954106450080872\n",
      "Epoch [90/100], Loss: 0.3040052354335785\n",
      "Epoch [100/100], Loss: 0.6213476657867432\n",
      "Accuracy: 0.7290076335877863%\n",
      "-----------------------------------------------------------------------\n",
      "CNN\n",
      "Epoch [10/100], Train Loss: 0.6695279507351316, Val Loss: 0.7230517600125413\n",
      "Epoch [20/100], Train Loss: 0.6334025032264142, Val Loss: 0.6963827190844993\n",
      "Epoch [30/100], Train Loss: 0.6134690756886458, Val Loss: 0.7602708237927135\n",
      "Epoch [40/100], Train Loss: 0.5928240727540875, Val Loss: 0.7964048322623338\n",
      "Epoch [50/100], Train Loss: 0.583049742397198, Val Loss: 0.7944052168508855\n",
      "Epoch [60/100], Train Loss: 0.5746754819204, Val Loss: 0.7801547845204672\n",
      "Epoch [70/100], Train Loss: 0.568429032325252, Val Loss: 0.7999672581994437\n",
      "Epoch [80/100], Train Loss: 0.5620426817620097, Val Loss: 0.7912992900464593\n",
      "Epoch [90/100], Train Loss: 0.553691752378113, Val Loss: 0.8065253035808967\n",
      "Epoch [100/100], Train Loss: 0.5507357249821513, Val Loss: 0.8679250721039811\n",
      "Accuracy of CNN: 0.7175572519083969\n",
      "-----------------------------------------------------------------------\n",
      "RNN\n",
      "Epoch 5/150, Train Loss: 0.7767115170059126, Val Loss: 0.7591535495064123\n",
      "Epoch 10/150, Train Loss: 0.6819087461499144, Val Loss: 0.6845589580574656\n",
      "Epoch 15/150, Train Loss: 0.6360660488447867, Val Loss: 0.6722698928864022\n",
      "Epoch 20/150, Train Loss: 0.6021221674178258, Val Loss: 0.8511003238883444\n",
      "Epoch 25/150, Train Loss: 0.5810115231462747, Val Loss: 0.8011422428658338\n",
      "Epoch 30/150, Train Loss: 0.5653606553461926, Val Loss: 0.7758450542039018\n",
      "Epoch 35/150, Train Loss: 0.5558439993168697, Val Loss: 0.8048075914867525\n",
      "Epoch 40/150, Train Loss: 0.548350550603768, Val Loss: 0.8281281503235421\n",
      "Epoch 45/150, Train Loss: 0.5406414726672094, Val Loss: 0.8163348620500022\n",
      "Epoch 50/150, Train Loss: 0.534966371337737, Val Loss: 0.8154774606227875\n",
      "Epoch 55/150, Train Loss: 0.5282375301457634, Val Loss: 0.8595110822499283\n",
      "Epoch 60/150, Train Loss: 0.5234816866226433, Val Loss: 0.8485422914590293\n",
      "Epoch 65/150, Train Loss: 0.5159412849047953, Val Loss: 0.9090978202781057\n",
      "Epoch 70/150, Train Loss: 0.5057011597043226, Val Loss: 0.8803645205206987\n",
      "Epoch 75/150, Train Loss: 0.49394156457471455, Val Loss: 0.8943862280225366\n",
      "Epoch 80/150, Train Loss: 0.4854151595476245, Val Loss: 0.8590822549370246\n",
      "Epoch 85/150, Train Loss: 0.4803258042074432, Val Loss: 0.8570033144660112\n",
      "Epoch 90/150, Train Loss: 0.4693470721032994, Val Loss: 0.8864079209847179\n",
      "Epoch 95/150, Train Loss: 0.45558707416057587, Val Loss: 0.921795710073254\n",
      "Epoch 100/150, Train Loss: 0.44847336516153713, Val Loss: 0.9879926954343067\n",
      "Epoch 105/150, Train Loss: 0.4376140932652576, Val Loss: 0.9236101333687945\n",
      "Epoch 110/150, Train Loss: 0.42667646638371726, Val Loss: 0.9873176580522118\n",
      "Epoch 115/150, Train Loss: 0.4155320477756587, Val Loss: 0.9287903098071494\n",
      "Epoch 120/150, Train Loss: 0.40855213673400487, Val Loss: 0.9576672082994042\n",
      "Epoch 125/150, Train Loss: 0.3933513613094476, Val Loss: 0.978847314429477\n",
      "Epoch 130/150, Train Loss: 0.382346871655342, Val Loss: 1.0173279584907904\n",
      "Epoch 135/150, Train Loss: 0.3665544332182112, Val Loss: 1.0248476913789424\n",
      "Epoch 140/150, Train Loss: 0.3547162661436668, Val Loss: 1.0455460492672959\n",
      "Epoch 145/150, Train Loss: 0.33993579853664746, Val Loss: 1.1117041888760357\n",
      "Epoch 150/150, Train Loss: 0.32925028163046877, Val Loss: 1.1715896248332853\n",
      "Accuracy of RNN: 0.6712468193384223\n",
      "-----------------------------------------------------------------------\n",
      "TESTING WITH 8 PHASES...\n",
      "[26 28  8 27  9]\n",
      "Train data: Extracted 10312 samples with 5 features each.\n",
      "Test data: Extracted 5240 samples with 5 features each.\n",
      "-----------------------------------------------------------------------\n",
      "Simple NN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.7411975860595703\n",
      "Epoch [20/100], Loss: 0.8029157519340515\n",
      "Epoch [30/100], Loss: 1.3836233615875244\n",
      "Epoch [40/100], Loss: 1.5546725988388062\n",
      "Epoch [50/100], Loss: 1.0263904333114624\n",
      "Epoch [60/100], Loss: 1.341202735900879\n",
      "Epoch [70/100], Loss: 0.9783419966697693\n",
      "Epoch [80/100], Loss: 0.9092841744422913\n",
      "Epoch [90/100], Loss: 0.9814821481704712\n",
      "Epoch [100/100], Loss: 0.9890117645263672\n",
      "Accuracy: 0.49446564885496186%\n",
      "-----------------------------------------------------------------------\n",
      "CNN\n",
      "Epoch [10/100], Train Loss: 1.1282502523516722, Val Loss: 1.2140975819855202\n",
      "Epoch [20/100], Train Loss: 1.0721264618100028, Val Loss: 1.1891033184237596\n",
      "Epoch [30/100], Train Loss: 1.048373462061395, Val Loss: 1.184344907722822\n",
      "Epoch [40/100], Train Loss: 1.0258272902884351, Val Loss: 1.1858930253401034\n",
      "Epoch [50/100], Train Loss: 1.0099987916348518, Val Loss: 1.186248037509802\n",
      "Epoch [60/100], Train Loss: 1.0002240156610684, Val Loss: 1.2234143763780594\n",
      "Epoch [70/100], Train Loss: 0.9928158553023088, Val Loss: 1.2011771325658007\n",
      "Epoch [80/100], Train Loss: 0.9860394853556488, Val Loss: 1.2036138373177225\n",
      "Epoch [90/100], Train Loss: 0.9761718057626542, Val Loss: 1.181639099266471\n",
      "Epoch [100/100], Train Loss: 0.9704116267316482, Val Loss: 1.238756291023115\n",
      "Accuracy of CNN: 0.48244274809160304\n",
      "-----------------------------------------------------------------------\n",
      "RNN\n",
      "Epoch 5/150, Train Loss: 1.2834207109253473, Val Loss: 1.3589721852686347\n",
      "Epoch 10/150, Train Loss: 1.2405080326570446, Val Loss: 1.2608728012660655\n",
      "Epoch 15/150, Train Loss: 1.1144223024970608, Val Loss: 1.3134297583161332\n",
      "Epoch 20/150, Train Loss: 1.0661994392288727, Val Loss: 1.1993041928948425\n",
      "Epoch 25/150, Train Loss: 1.0406861882829814, Val Loss: 1.1857149215733134\n",
      "Epoch 30/150, Train Loss: 1.0074263654257123, Val Loss: 1.1607568053210653\n",
      "Epoch 35/150, Train Loss: 0.9932909659556929, Val Loss: 1.1793782721932342\n",
      "Epoch 40/150, Train Loss: 0.9839225134613344, Val Loss: 1.1744653110097094\n",
      "Epoch 45/150, Train Loss: 0.9778800547676559, Val Loss: 1.1740668743121914\n",
      "Epoch 50/150, Train Loss: 0.9615469261219627, Val Loss: 1.1987608420412714\n",
      "Epoch 55/150, Train Loss: 0.9556293633331087, Val Loss: 1.2053585812086012\n",
      "Epoch 60/150, Train Loss: 0.9471516062969763, Val Loss: 1.2037484256959543\n",
      "Epoch 65/150, Train Loss: 0.9430186694989633, Val Loss: 1.203370138275914\n",
      "Epoch 70/150, Train Loss: 0.9339225447214794, Val Loss: 1.2476777001851942\n",
      "Epoch 75/150, Train Loss: 0.9228033203827707, Val Loss: 1.2280756940202016\n",
      "Epoch 80/150, Train Loss: 0.9159251346307642, Val Loss: 1.2202376156318477\n",
      "Epoch 85/150, Train Loss: 0.905663821627112, Val Loss: 1.2363103399189508\n",
      "Epoch 90/150, Train Loss: 0.8985910491308561, Val Loss: 1.2777118741012201\n",
      "Epoch 95/150, Train Loss: 0.8910265332405043, Val Loss: 1.2173902410559538\n",
      "Epoch 100/150, Train Loss: 0.8797213861447739, Val Loss: 1.2380191861856273\n",
      "Epoch 105/150, Train Loss: 0.8748021091654574, Val Loss: 1.2266446897169438\n",
      "Epoch 110/150, Train Loss: 0.8587671939064475, Val Loss: 1.2631877079242613\n",
      "Epoch 115/150, Train Loss: 0.8523077126996067, Val Loss: 1.2658055584605148\n",
      "Epoch 120/150, Train Loss: 0.8367696552084696, Val Loss: 1.2826492484749816\n",
      "Epoch 125/150, Train Loss: 0.8292059571750393, Val Loss: 1.292154691204792\n",
      "Epoch 130/150, Train Loss: 0.8202570280054405, Val Loss: 1.2978381874357783\n",
      "Epoch 135/150, Train Loss: 0.8085933176356572, Val Loss: 1.3115682071301995\n",
      "Epoch 140/150, Train Loss: 0.7966604548342088, Val Loss: 1.3245532022016804\n",
      "Epoch 145/150, Train Loss: 0.7844109521377197, Val Loss: 1.340016879686495\n",
      "Epoch 150/150, Train Loss: 0.7698254787331396, Val Loss: 1.360830156904895\n",
      "Accuracy of RNN: 0.47080152671755726\n",
      "-----------------------------------------------------------------------\n",
      "TESTING WITH 10 PHASES...\n",
      "[26 27  9 28  7]\n",
      "Train data: Extracted 12890 samples with 5 features each.\n",
      "Test data: Extracted 6550 samples with 5 features each.\n",
      "-----------------------------------------------------------------------\n",
      "Simple NN\n",
      "Epoch [10/100], Loss: 1.3812503814697266\n",
      "Epoch [20/100], Loss: 1.1633671522140503\n",
      "Epoch [30/100], Loss: 1.0006327629089355\n",
      "Epoch [40/100], Loss: 1.172522783279419\n",
      "Epoch [50/100], Loss: 0.9293807148933411\n",
      "Epoch [60/100], Loss: 1.119490146636963\n",
      "Epoch [70/100], Loss: 0.9824050664901733\n",
      "Epoch [80/100], Loss: 1.6641758680343628\n",
      "Epoch [90/100], Loss: 0.9394331574440002\n",
      "Epoch [100/100], Loss: 1.3074467182159424\n",
      "Accuracy: 0.4398473282442748%\n",
      "-----------------------------------------------------------------------\n",
      "CNN\n",
      "Epoch [10/100], Train Loss: 1.4092671554674285, Val Loss: 1.4441602532456561\n",
      "Epoch [20/100], Train Loss: 1.3501177906398443, Val Loss: 1.4423390586201739\n",
      "Epoch [30/100], Train Loss: 1.307238560456496, Val Loss: 1.444927888381772\n",
      "Epoch [40/100], Train Loss: 1.2769758526799697, Val Loss: 1.4325179934501648\n",
      "Epoch [50/100], Train Loss: 1.2570457079866093, Val Loss: 1.4308701582071257\n",
      "Epoch [60/100], Train Loss: 1.2411854367693955, Val Loss: 1.4128014800025195\n",
      "Epoch [70/100], Train Loss: 1.2302234128450342, Val Loss: 1.4120264466215924\n",
      "Epoch [80/100], Train Loss: 1.2184042069811383, Val Loss: 1.4013537482517522\n",
      "Epoch [90/100], Train Loss: 1.211685529269888, Val Loss: 1.4159757803126078\n",
      "Epoch [100/100], Train Loss: 1.2061220092453968, Val Loss: 1.3932472499405466\n",
      "Accuracy of CNN: 0.4346564885496183\n",
      "-----------------------------------------------------------------------\n",
      "RNN\n",
      "Epoch 5/150, Train Loss: 1.5020574337199664, Val Loss: 1.5118049197080659\n",
      "Epoch 10/150, Train Loss: 1.4146172762212919, Val Loss: 1.4337370003142007\n",
      "Epoch 15/150, Train Loss: 1.2891712664966253, Val Loss: 1.414061098563962\n",
      "Epoch 20/150, Train Loss: 1.2493582974296646, Val Loss: 1.3816973418724245\n",
      "Epoch 25/150, Train Loss: 1.2287888171950878, Val Loss: 1.4079927040309441\n",
      "Epoch 30/150, Train Loss: 1.209106919043709, Val Loss: 1.3889398507955597\n",
      "Epoch 35/150, Train Loss: 1.197331566816524, Val Loss: 1.4141737353510972\n",
      "Epoch 40/150, Train Loss: 1.1859050152023731, Val Loss: 1.4569300090394368\n",
      "Epoch 45/150, Train Loss: 1.1777106455478716, Val Loss: 1.4705626609848768\n",
      "Epoch 50/150, Train Loss: 1.1681880842959023, Val Loss: 1.4115960417724238\n",
      "Epoch 55/150, Train Loss: 1.1597960875288724, Val Loss: 1.4214226993118844\n",
      "Epoch 60/150, Train Loss: 1.1525572150871712, Val Loss: 1.4662495996893905\n",
      "Epoch 65/150, Train Loss: 1.1416610112557044, Val Loss: 1.4697490378123959\n",
      "Epoch 70/150, Train Loss: 1.1294099167913716, Val Loss: 1.4482684481434707\n",
      "Epoch 75/150, Train Loss: 1.122271013466951, Val Loss: 1.480648514701099\n",
      "Epoch 80/150, Train Loss: 1.1108436609616055, Val Loss: 1.4593058475633947\n",
      "Epoch 85/150, Train Loss: 1.1002249543187637, Val Loss: 1.4889239665938587\n",
      "Epoch 90/150, Train Loss: 1.090604892883348, Val Loss: 1.4625972651853794\n",
      "Epoch 95/150, Train Loss: 1.0770770508065708, Val Loss: 1.4958927535429234\n",
      "Epoch 100/150, Train Loss: 1.0682818852642333, Val Loss: 1.4932040505292938\n",
      "Epoch 105/150, Train Loss: 1.0571360993326153, Val Loss: 1.5223490203299173\n",
      "Epoch 110/150, Train Loss: 1.0466042805842075, Val Loss: 1.5087114674289053\n",
      "Epoch 115/150, Train Loss: 1.032531126705056, Val Loss: 1.513252991583289\n",
      "Epoch 120/150, Train Loss: 1.0196835107306392, Val Loss: 1.5725037624196307\n",
      "Epoch 125/150, Train Loss: 1.0088681075768198, Val Loss: 1.5838068712048414\n",
      "Epoch 130/150, Train Loss: 0.9923140202503347, Val Loss: 1.607077795993991\n",
      "Epoch 135/150, Train Loss: 0.9835273190112622, Val Loss: 1.5836791590946477\n",
      "Epoch 140/150, Train Loss: 0.9689179227014925, Val Loss: 1.6148803094538247\n",
      "Epoch 145/150, Train Loss: 0.9522746121025559, Val Loss: 1.6254131700934433\n",
      "Epoch 150/150, Train Loss: 0.9378405187473108, Val Loss: 1.6528085987742354\n",
      "Accuracy of RNN: 0.40091603053435115\n",
      "-----------------------------------------------------------------------\n",
      "TESTING WITH 12 PHASES...\n",
      "[27  8 26 28  9]\n",
      "Train data: Extracted 15468 samples with 5 features each.\n",
      "Test data: Extracted 7860 samples with 5 features each.\n",
      "-----------------------------------------------------------------------\n",
      "Simple NN\n",
      "Epoch [10/100], Loss: 1.7335591316223145\n",
      "Epoch [20/100], Loss: 1.4507137537002563\n",
      "Epoch [30/100], Loss: 1.6813706159591675\n",
      "Epoch [40/100], Loss: 2.0076792240142822\n",
      "Epoch [50/100], Loss: 1.6475787162780762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Loss: 1.438555121421814\n",
      "Epoch [70/100], Loss: 1.3262298107147217\n",
      "Epoch [80/100], Loss: 1.875027060508728\n",
      "Epoch [90/100], Loss: 1.0514928102493286\n",
      "Epoch [100/100], Loss: 1.315033197402954\n",
      "Accuracy: 0.3278625954198473%\n",
      "-----------------------------------------------------------------------\n",
      "CNN\n",
      "Epoch [10/100], Train Loss: 1.5723645320115995, Val Loss: 1.7447690920131962\n",
      "Epoch [20/100], Train Loss: 1.5217035563031505, Val Loss: 1.7480929760428947\n",
      "Epoch [30/100], Train Loss: 1.4990660673823237, Val Loss: 1.7383572139391086\n",
      "Epoch [40/100], Train Loss: 1.484052272621265, Val Loss: 1.7287688987041876\n",
      "Epoch [50/100], Train Loss: 1.4741289864394291, Val Loss: 1.7195617091364976\n",
      "Epoch [60/100], Train Loss: 1.464356103711877, Val Loss: 1.7284404994026432\n",
      "Epoch [70/100], Train Loss: 1.4551661930793574, Val Loss: 1.7321648844858495\n",
      "Epoch [80/100], Train Loss: 1.4515416845063533, Val Loss: 1.7120155881090862\n",
      "Epoch [90/100], Train Loss: 1.4465007562775256, Val Loss: 1.7037781724115697\n",
      "Epoch [100/100], Train Loss: 1.442482177999394, Val Loss: 1.7225215464103512\n",
      "Accuracy of CNN: 0.33155216284987277\n",
      "-----------------------------------------------------------------------\n",
      "RNN\n",
      "Epoch 5/150, Train Loss: 1.5668557936495, Val Loss: 1.7472287348615445\n",
      "Epoch 10/150, Train Loss: 1.509249531040507, Val Loss: 1.7066697042162826\n",
      "Epoch 15/150, Train Loss: 1.488458136142778, Val Loss: 1.7056513089474623\n",
      "Epoch 20/150, Train Loss: 1.473303845598678, Val Loss: 1.7230398611324589\n",
      "Epoch 25/150, Train Loss: 1.4629852463883801, Val Loss: 1.7307644190827036\n",
      "Epoch 30/150, Train Loss: 1.4506105251056103, Val Loss: 1.7658910765880491\n",
      "Epoch 35/150, Train Loss: 1.441042106259953, Val Loss: 1.7494240189955486\n",
      "Epoch 40/150, Train Loss: 1.4304650802750232, Val Loss: 1.7436055104906967\n",
      "Epoch 45/150, Train Loss: 1.4228550885334488, Val Loss: 1.7710922525181034\n",
      "Epoch 50/150, Train Loss: 1.4113077038575794, Val Loss: 1.755568143313493\n",
      "Epoch 55/150, Train Loss: 1.4007534235715866, Val Loss: 1.766452604677619\n",
      "Epoch 60/150, Train Loss: 1.3913880295989927, Val Loss: 1.7548986789656849\n",
      "Epoch 65/150, Train Loss: 1.3823529109974537, Val Loss: 1.7955993840364906\n",
      "Epoch 70/150, Train Loss: 1.3713692836771327, Val Loss: 1.8154944801718238\n",
      "Epoch 75/150, Train Loss: 1.3600325891055352, Val Loss: 1.7758727543722324\n",
      "Epoch 80/150, Train Loss: 1.3497852232337983, Val Loss: 1.8220321642674082\n",
      "Epoch 85/150, Train Loss: 1.3365687170058242, Val Loss: 1.8193023340488836\n",
      "Epoch 90/150, Train Loss: 1.3254832550267543, Val Loss: 1.8320674746017145\n",
      "Epoch 95/150, Train Loss: 1.3105802579113275, Val Loss: 1.8632431800772504\n",
      "Epoch 100/150, Train Loss: 1.298296707597646, Val Loss: 1.8679461425882045\n",
      "Epoch 105/150, Train Loss: 1.2838907848951244, Val Loss: 1.886795991319951\n",
      "Epoch 110/150, Train Loss: 1.2664475679890184, Val Loss: 1.90911382969802\n",
      "Epoch 115/150, Train Loss: 1.254367975533501, Val Loss: 1.9314986632122257\n",
      "Epoch 120/150, Train Loss: 1.2377086646300701, Val Loss: 1.946481951853124\n",
      "Epoch 125/150, Train Loss: 1.2234993996945294, Val Loss: 1.972182262719162\n",
      "Epoch 130/150, Train Loss: 1.2078854836954558, Val Loss: 1.9753204598659422\n",
      "Epoch 135/150, Train Loss: 1.1903492198749022, Val Loss: 1.9878830546286048\n",
      "Epoch 140/150, Train Loss: 1.1713230596347288, Val Loss: 2.036550569825056\n",
      "Epoch 145/150, Train Loss: 1.1572164859899805, Val Loss: 2.074007476248392\n",
      "Epoch 150/150, Train Loss: 1.1381884530063504, Val Loss: 2.0835693740263217\n",
      "Accuracy of RNN: 0.305089058524173\n",
      "-----------------------------------------------------------------------\n",
      "TESTING WITH 14 PHASES...\n",
      "[27  9 28 26  7]\n",
      "Train data: Extracted 18046 samples with 5 features each.\n",
      "Test data: Extracted 9170 samples with 5 features each.\n",
      "-----------------------------------------------------------------------\n",
      "Simple NN\n",
      "Epoch [10/100], Loss: 1.8095942735671997\n",
      "Epoch [20/100], Loss: 1.5529354810714722\n",
      "Epoch [30/100], Loss: 1.7994104623794556\n",
      "Epoch [40/100], Loss: 1.5362951755523682\n",
      "Epoch [50/100], Loss: 1.5496635437011719\n",
      "Epoch [60/100], Loss: 1.5337756872177124\n",
      "Epoch [70/100], Loss: 1.612016201019287\n",
      "Epoch [20/100], Train Loss: 1.7042579557878752, Val Loss: 1.904951900970645\n",
      "Epoch [30/100], Train Loss: 1.6689327739654702, Val Loss: 1.8668332548506998\n",
      "Epoch [40/100], Train Loss: 1.6508270806454597, Val Loss: 1.8685267814775792\n",
      "Epoch [50/100], Train Loss: 1.637951763175058, Val Loss: 1.8626524563035067\n",
      "Epoch [60/100], Train Loss: 1.6309204200903575, Val Loss: 1.8773646167761773\n",
      "Epoch [70/100], Train Loss: 1.6250819005864732, Val Loss: 1.8598835048775224\n",
      "Epoch [80/100], Train Loss: 1.619977020836891, Val Loss: 1.872471577614442\n",
      "Epoch [90/100], Train Loss: 1.6172464525868706, Val Loss: 1.8513941906055091\n",
      "Epoch [100/100], Train Loss: 1.6123300152467497, Val Loss: 1.8628585247212586\n",
      "Accuracy of CNN: 0.30523446019629225\n",
      "-----------------------------------------------------------------------\n",
      "RNN\n",
      "Epoch 5/150, Train Loss: 1.787377985868048, Val Loss: 2.022908025502328\n",
      "Epoch 10/150, Train Loss: 1.689025473298756, Val Loss: 1.8787035663784173\n",
      "Epoch 15/150, Train Loss: 1.6559564938359226, Val Loss: 1.8829883839610562\n",
      "Epoch 20/150, Train Loss: 1.64047424484652, Val Loss: 1.8634605856307291\n",
      "Epoch 25/150, Train Loss: 1.6231121374360213, Val Loss: 1.875254199064567\n",
      "Epoch 30/150, Train Loss: 1.6137622558901497, Val Loss: 1.8702595088540055\n",
      "Epoch 35/150, Train Loss: 1.6004322517848184, Val Loss: 1.8978041979493996\n",
      "Epoch 40/150, Train Loss: 1.5880885959094297, Val Loss: 1.8886920305079284\n",
      "Epoch 45/150, Train Loss: 1.581322432621151, Val Loss: 1.895145321141552\n",
      "Epoch 50/150, Train Loss: 1.5707479812574725, Val Loss: 1.9418682628392343\n",
      "Epoch 55/150, Train Loss: 1.5624551119956565, Val Loss: 1.914902357689595\n",
      "Epoch 60/150, Train Loss: 1.5535497959201217, Val Loss: 1.9803089202488757\n",
      "Epoch 65/150, Train Loss: 1.5399664456539965, Val Loss: 1.915214293925189\n",
      "Epoch 70/150, Train Loss: 1.5291981061933735, Val Loss: 1.916215566807923\n",
      "Epoch 75/150, Train Loss: 1.5192355418458898, Val Loss: 1.9257018001237398\n",
      "Epoch 80/150, Train Loss: 1.5063731675663738, Val Loss: 1.949118412745539\n",
      "Epoch 85/150, Train Loss: 1.4929310372957947, Val Loss: 1.9399982686657524\n",
      "Epoch 90/150, Train Loss: 1.4788899010588936, Val Loss: 1.9844532307847451\n",
      "Epoch 95/150, Train Loss: 1.4678519878615723, Val Loss: 2.0047751847875244\n",
      "Epoch 100/150, Train Loss: 1.457060269113128, Val Loss: 2.010630452259077\n",
      "Epoch 105/150, Train Loss: 1.442201960382732, Val Loss: 2.0298419164863613\n",
      "Epoch 110/150, Train Loss: 1.4303920936922656, Val Loss: 2.0266464026547477\n",
      "Epoch 115/150, Train Loss: 1.4142825083529695, Val Loss: 2.0960401637213573\n",
      "Epoch 120/150, Train Loss: 1.4022941276536767, Val Loss: 2.0668181558934653\n",
      "Epoch 125/150, Train Loss: 1.391053686856378, Val Loss: 2.0933410921993985\n",
      "Epoch 130/150, Train Loss: 1.3766087317931737, Val Loss: 2.0908544009570877\n",
      "Epoch 135/150, Train Loss: 1.3635354386576524, Val Loss: 2.1116250221737585\n",
      "Epoch 140/150, Train Loss: 1.3492550172492968, Val Loss: 2.138444904250966\n",
      "Epoch 145/150, Train Loss: 1.3335370848364865, Val Loss: 2.153751655738113\n",
      "Epoch 150/150, Train Loss: 1.3190509760422064, Val Loss: 2.1879334117477365\n",
      "Accuracy of RNN: 0.27284623773173394\n",
      "-----------------------------------------------------------------------\n",
      "TESTING WITH 16 PHASES...\n",
      "[27  9 26 28  7]\n",
      "Train data: Extracted 20624 samples with 5 features each.\n",
      "Test data: Extracted 10480 samples with 5 features each.\n",
      "-----------------------------------------------------------------------\n",
      "Simple NN\n",
      "Epoch [10/100], Loss: 1.8030381202697754\n",
      "Epoch [20/100], Loss: 1.864332675933838\n",
      "Epoch [30/100], Loss: 1.546610951423645\n",
      "Epoch [40/100], Loss: 1.915665626525879\n",
      "Epoch [50/100], Loss: 1.827916145324707\n",
      "Epoch [60/100], Loss: 3.199617862701416\n",
      "Epoch [70/100], Loss: 1.8626773357391357\n",
      "Epoch [80/100], Loss: 1.850786805152893\n",
      "Epoch [90/100], Loss: 1.6163887977600098\n",
      "Epoch [100/100], Loss: 2.588163137435913\n",
      "Accuracy: 0.26288167938931295%\n",
      "-----------------------------------------------------------------------\n",
      "CNN\n",
      "Epoch [10/100], Train Loss: 1.9677023072575415, Val Loss: 2.0702606686731664\n",
      "Epoch [20/100], Train Loss: 1.9080715647039488, Val Loss: 2.056580861530653\n",
      "Epoch [30/100], Train Loss: 1.874014142502186, Val Loss: 2.0323024134083494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Train Loss: 1.8589500351469646, Val Loss: 2.0250981566382618\n",
      "Epoch [50/100], Train Loss: 1.8464743203895038, Val Loss: 2.022738781280634\n",
      "Epoch [60/100], Train Loss: 1.8404945538025494, Val Loss: 2.0613836482530687\n",
      "Epoch [70/100], Train Loss: 1.8363509873087092, Val Loss: 2.0167386775336613\n",
      "Epoch [80/100], Train Loss: 1.8283852978270183, Val Loss: 2.0251910701030638\n",
      "Epoch [90/100], Train Loss: 1.8222959448200788, Val Loss: 2.0127688987952905\n",
      "Epoch [100/100], Train Loss: 1.820206405950147, Val Loss: 2.0157938599586487\n",
      "Accuracy of CNN: 0.2583969465648855\n",
      "-----------------------------------------------------------------------\n",
      "RNN\n",
      "Epoch 5/150, Train Loss: 1.997800713731337, Val Loss: 2.0933684659440344\n",
      "Epoch 10/150, Train Loss: 1.8854786837747854, Val Loss: 2.012128849218531\n",
      "Epoch 15/150, Train Loss: 1.8581903923389524, Val Loss: 1.9834106019357356\n",
      "Epoch 20/150, Train Loss: 1.8393411590147388, Val Loss: 2.0172652729400773\n",
      "Epoch 25/150, Train Loss: 1.8275355666182762, Val Loss: 2.023887918853178\n",
      "Epoch 30/150, Train Loss: 1.8167555884797444, Val Loss: 2.0237214946892204\n",
      "Epoch 35/150, Train Loss: 1.8081508701161821, Val Loss: 2.03103414105206\n",
      "Epoch 40/150, Train Loss: 1.7963807176249895, Val Loss: 2.0261863142978855\n",
      "Epoch 45/150, Train Loss: 1.7856762714164203, Val Loss: 2.033254456229326\n",
      "Epoch 50/150, Train Loss: 1.7760448448417723, Val Loss: 2.0440984651809786\n",
      "Epoch 55/150, Train Loss: 1.7679284149362136, Val Loss: 2.025212329335329\n",
      "Epoch 60/150, Train Loss: 1.7574990050737247, Val Loss: 2.075134895196775\n",
      "Epoch 65/150, Train Loss: 1.7480844773063364, Val Loss: 2.0768189797314203\n",
      "Epoch 70/150, Train Loss: 1.7368265961491784, Val Loss: 2.0839660029585767\n",
      "Epoch 75/150, Train Loss: 1.7271124409150707, Val Loss: 2.084965696785508\n",
      "Epoch 80/150, Train Loss: 1.7138547505519186, Val Loss: 2.092693823866728\n",
      "Epoch 85/150, Train Loss: 1.7029147918834242, Val Loss: 2.113137028202778\n",
      "Epoch 90/150, Train Loss: 1.691524427436119, Val Loss: 2.111696837878809\n",
      "Epoch 95/150, Train Loss: 1.6797193739765375, Val Loss: 2.120921246162275\n",
      "Epoch 100/150, Train Loss: 1.6690276508183441, Val Loss: 2.14484110910718\n",
      "Epoch 105/150, Train Loss: 1.654011105566986, Val Loss: 2.1664147329766577\n",
      "Epoch 110/150, Train Loss: 1.6425175633541373, Val Loss: 2.17271148940412\n",
      "Epoch 115/150, Train Loss: 1.6290079007777132, Val Loss: 2.19013791731218\n",
      "Epoch 120/150, Train Loss: 1.6158791810043098, Val Loss: 2.2174520445306127\n"
     ]
    }
   ],
   "source": [
    "for num_fases in fases_to_test:\n",
    "    print(f\"TESTING WITH {num_fases} PHASES...\")\n",
    "    \n",
    "    train_data, train_labels, test_data, test_labels, train_feature_names, test_feature_names = prepare_training_and_testing(emg, file, C=[0,1,2], divide=3, num_fases=num_fases)\n",
    "    train_data, test_data = clean_normalized_feature_selection(train_data, test_data)\n",
    "    train_data, test_data = sfs_selection(train_data,test_data,train_labels,n_indices=5)\n",
    "    print(f\"Train data: Extracted {train_data.shape[0]} samples with {train_data.shape[1]} features each.\")\n",
    "    print(f\"Test data: Extracted {test_data.shape[0]} samples with {test_data.shape[1]} features each.\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "    # Simple NN\n",
    "    print(\"Simple NN\")\n",
    "    input_size = train_data.shape[1]\n",
    "    hidden_size = 100\n",
    "    output_size = num_fases\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 100\n",
    "    \n",
    "    model = SimpleNN(input_size, hidden_size, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loader, test_tensor, test_labels_tensor = prepare_data_SimpleNN(train_data, train_labels, test_data, test_labels)\n",
    "    train_model_SimpleNN(model, criterion, optimizer, train_loader, num_epochs)\n",
    "    accuracy_nn = evaluate_model_SimpleNN(model, test_tensor, test_labels_tensor)\n",
    "    results_simple_nn.append((num_fases, accuracy_nn))\n",
    "\n",
    "    # CNN\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"CNN\")\n",
    "    train_loader, test_loader, test_labels_tensor, train_data_tensor = prepare_data_CNN(train_data, train_labels, test_data, test_labels)\n",
    "    input_length = train_data_tensor.shape[2]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    cnn_model = GaitCNN(input_length, num_fases=num_fases).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loss, test_loss = train_model_CNN(cnn_model, device, criterion, optimizer, train_loader, test_loader, num_epochs=100)\n",
    "    accuracy_cnn = evaluate_model_CNN(cnn_model, test_loader, test_labels_tensor)\n",
    "    results_cnn.append((num_fases, accuracy_cnn))\n",
    "\n",
    "    # RNN\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"RNN\")\n",
    "    train_data_rnn, test_data_rnn = preprocess_data_RNN(train_data, test_data)\n",
    "    input_size = train_data_rnn.shape[2]\n",
    "    hidden_size = 64\n",
    "    num_layers = 2\n",
    "    batch_size = 32\n",
    "    num_epochs = 150\n",
    "    \n",
    "    train_loader, test_loader = create_dataloaders_RNN(train_data_rnn, train_labels, test_data_rnn, test_labels, batch_size)\n",
    "    rnn_model = GaitRNN(input_size, hidden_size, num_layers, num_fases).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loss, test_loss = train_model_RNN(rnn_model, train_loader, test_loader, criterion, optimizer, num_epochs, device)\n",
    "    accuracy_rnn = evaluate_model_RNN(rnn_model, test_loader, test_labels, device)\n",
    "    results_rnn.append((num_fases, accuracy_rnn))\n",
    "    print(\"-----------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-21T15:20:30.243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar los resultados\n",
    "print(\"Results for Simple NN:\")\n",
    "for num_fases, acc in results_simple_nn:\n",
    "    print(f\"Phases: {num_fases}, Accuracy: {acc}\")\n",
    "\n",
    "print(\"Results for CNN:\")\n",
    "for num_fases, acc in results_cnn:\n",
    "    print(f\"Phases: {num_fases}, Accuracy: {acc}\")\n",
    "\n",
    "print(\"Results for RNN:\")\n",
    "for num_fases, acc in results_rnn:\n",
    "    print(f\"Phases: {num_fases}, Accuracy: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
